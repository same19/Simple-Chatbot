{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for generating train and test data from WT2 and WT103 datasets.\n",
    "\n",
    "Sources:\n",
    "\n",
    "https://towardsdatascience.com/word2vec-with-pytorch-implementing-original-paper-2cd7040120b0\n",
    "\n",
    "https://towardsdatascience.com/running-jupyter-notebook-on-the-cloud-in-15-mins-azure-79b7797e4ef6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import WikiText2\n",
    "import pandas as pd\n",
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "wikitext2 = load_dataset(\"wikitext\", \"wikitext-2-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_SPLIT = \"test\"\n",
    "text = wikitext2[DATA_SPLIT]['text']\n",
    "text = [item.lower().strip() for item in text if len(item) > 0]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [item.split(\" \") + [\"\\n\"] for item in text if \"=\" not in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023109"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare Corpus\n",
    "DATA_LIMIT = None #paragraph limit\n",
    "all_words = []\n",
    "for paragraph in text[:DATA_LIMIT]:\n",
    "    all_words += paragraph\n",
    "all_words = pd.Series(all_words)\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28909"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_paragraphs = [pd.Series(p).unique() for p in text]\n",
    "l = []\n",
    "for p in unique_paragraphs:\n",
    "    l += list(p)\n",
    "v_counts = pd.Series(l).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   \\n\n",
       "1                    ,\n",
       "2                    .\n",
       "3                  the\n",
       "4                   of\n",
       "             ...      \n",
       "1751         sustained\n",
       "1752          historic\n",
       "1753           failure\n",
       "1754    administration\n",
       "1755              1987\n",
       "Length: 1756, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter out rare words\n",
    "N_times = 100 #shows up in 100 different paragraphs\n",
    "# v_counts = all_words.value_counts()\n",
    "corpus = pd.Series([key for key in v_counts.keys() if v_counts[key] >= N_times])\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1756"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "for i in range(len(corpus)):\n",
    "    vocab[corpus[i]] = i\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"may1_WT2_nodatalim_20epoch_64dim_100minpf_2window\"\n",
    "torch.save(vocab, f\"saves/vocab_{version}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2176"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_text = [[vocab[word] if word in vocab else vocab[\"<unk>\"] for word in paragraph] for paragraph in text]\n",
    "len(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNING_WINDOW = 2\n",
    "#maybe need to split into paragraphs b/c different topics...\n",
    "#returns context, middle word\n",
    "def get_data(index, window, data):\n",
    "    return list(data[index-window:index])+list(data[index+1:index+window+1]), data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "••••••••••••••••"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "count = 0\n",
    "for paragraph in enc_text:\n",
    "    if count % (len(enc_text)//16) == 0:\n",
    "        print(\"•\", end=\"\")\n",
    "    for i in range(SCANNING_WINDOW, len(paragraph) - SCANNING_WINDOW):\n",
    "        if paragraph[i] == vocab[\"<unk>\"]:\n",
    "            continue\n",
    "        a, b = get_data(i, SCANNING_WINDOW, paragraph)\n",
    "        x.append(a)\n",
    "        y.append(b)\n",
    "    count+=1\n",
    "    \n",
    "torch.save(x, f\"train_data/{DATA_SPLIT}_data_x_wt2_window2_100minpf.pt\")\n",
    "torch.save(y, f\"train_data/{DATA_SPLIT}_data_y_wt2_window2_100minpf.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
