{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nltk.org/book/ch05.html\n",
    "\n",
    "Need to reduce more common words...\n",
    "\n",
    "Need to prevent overfitting. Keeps predicting the same word for every possible input.\n",
    "\n",
    "Replace mean squared with mean cube/fourth? Something to prioritize the largest errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import words\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    # sno = nltk.stem.SnowballStemmer('english')\n",
    "    ps = WordNetLemmatizer()\n",
    "    stem = ps.lemmatize(word)\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15114"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "len(pd.Series(brown_news_tagged).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc = [word for word in brown_news_tagged if word[1] != \".\"]\n",
    "text = [word[0].lower() for word in remove_punc][:5000]\n",
    "# text = word_tokenize(open(\"text.txt\", \"r\").readline())\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(text).value_counts()[\"called\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1646"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.Series([word for word in text]).unique()\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = {}\n",
    "dim = len(corpus)\n",
    "for i in range(len(corpus)):\n",
    "    #frequent word subsampling\n",
    "    word_frequency = pd.Series(text).value_counts()[corpus[i]]/len(text)\n",
    "    t = 0.02\n",
    "    subsample_rate = (t/word_frequency)**0.5\n",
    "\n",
    "    vecs[corpus[i]] = [subsample_rate if i == j else 0.0 for j in range(len(corpus))]\n",
    "    # vecs[corpus[i]] = [1.0 if i == j else 0.0 for j in range(len(corpus))]\n",
    "    #vecs[word] = np.random(dim)*2-np.ones(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, in_len):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2*in_len, 128) #to embedding layer (the internal representation of the input word)\n",
    "        self.fc2 = nn.Linear(128, in_len, bias=False) #to output (word before, word after)\n",
    "    def forward(self, x):\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    def embeddings(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    def loss_score(self, x, y):\n",
    "        l = 0\n",
    "        for i in range(len(x)):\n",
    "            output = self(x[i])\n",
    "            target = y[i]\n",
    "            criterion_temp = nn.MSELoss()\n",
    "            loss = criterion_temp(output, target)\n",
    "            l += loss.item()/len(x)\n",
    "        return l\n",
    "net = Net(len(corpus))\n",
    "\n",
    "params = list(net.parameters())\n",
    "\n",
    "net.zero_grad()\n",
    "\n",
    "def criterion(input, target):\n",
    "    return sum((a-b)**3 for a,b in zip(input, target))/len(input)\n",
    "nn.MSELoss()\n",
    "# nn.CosineEmbeddingLoss()\n",
    "# nn.MSELoss()\n",
    "# nn.BCELoss\n",
    "# nn.LocalResponseNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4990"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "individual_words = text\n",
    "word_dict = vecs\n",
    "\n",
    "scanning_window = 5\n",
    "# for i in range(1,len(individual_words)-1):\n",
    "#     x.append(torch.tensor(word_dict[individual_words[i]]))\n",
    "#     y.append(torch.tensor(word_dict[individual_words[i-1]] + word_dict[individual_words[i+1]]))\n",
    "x = np.zeros(len(individual_words)-2*scanning_window)\n",
    "y = np.zeros(len(individual_words)-2*scanning_window)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "losses = []\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(index, window = 10, data=individual_words):\n",
    "    input_list = word_dict[data[index+window]]\n",
    "    o0 = np.zeros(len(corpus))\n",
    "    for i in range(-window, 0):\n",
    "        if index + i >= 0:\n",
    "            o0 += np.array(word_dict[data[index + i + window]]) * np.exp((i/window)**2 * -2)\n",
    "    o1 = np.zeros(len(corpus))\n",
    "    for i in range(1, window+1):\n",
    "        if index + i < len(data):\n",
    "            o1 += np.array(word_dict[data[index + i + window]]) * np.exp((i/window)**2 * -2)\n",
    "\n",
    "    # o0 *= 1/((sum(x**2 for x in o0))**0.5)\n",
    "    # o1 *= 1/((sum(x**2 for x in o1))**0.5)\n",
    "    return torch.tensor([float(a) for a in input_list]), torch.tensor([float(a) for a in (list(o0) + list(o1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 1/2: •••••••••••••••••••••\n",
      "RUN 2/2: •••••••••••••••••••••\n"
     ]
    }
   ],
   "source": [
    "NUM_RUNS = 2\n",
    "for run_num in range(NUM_RUNS):\n",
    "    print(\"RUN\", str(run_num+1)+\"/\"+str(NUM_RUNS), end=\": \")\n",
    "    for i in range(0,len(x_train),1):\n",
    "        if i % (len(x_train)//20) == 0:\n",
    "            print(\"•\", end=\"\")\n",
    "\n",
    "        # input = x_train[i]\n",
    "        # target = y_train[i]\n",
    "        target, input = generate_training_data(i, window = scanning_window)\n",
    "        if np.random.random() < 1 - max(target):\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output = net(input)\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "    # plt.plot(losses)\n",
    "    # plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# N_test = 100\n",
    "# print(net.loss_score(x_test, y_test))\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_around(word):\n",
    "    return net(word)\n",
    "\n",
    "# l = words_around(torch.tensor(word_dict[\"live\"]))\n",
    "# # l1 = l[:len(l)//2]\n",
    "# l1 = l[len(l)//2:]\n",
    "# max_index = -1\n",
    "# for i in range(len(l1)):\n",
    "#     if l1[i] >= l1[max_index]:\n",
    "#         max_index = i\n",
    "# print(corpus[max_index])\n",
    "# print(l1[max_index].item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there',\n",
       " 'is',\n",
       " 'person',\n",
       " 'planning',\n",
       " 'to',\n",
       " 'do',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '7.5',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the']"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_11_words = \"there is person planning to do the the the the the the the the the\"\n",
    "gen = text_11_words.split(\" \")\n",
    "for i in range(5):\n",
    "    input, output = generate_training_data(i, window=scanning_window, data=gen)\n",
    "    o = net(output)\n",
    "    o = list(o[:len(o)//2]) + list(0.1*torch.ones_like(o[len(o)//2:]))\n",
    "    max_i = -1\n",
    "    for i in range(len(o)):\n",
    "        if o[i].item() > o[max_i].item():\n",
    "            max_i = i\n",
    "    max_i\n",
    "    gen.insert(scanning_window+1, corpus[max_i])\n",
    "\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.5'"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = -1*torch.ones(2*len(corpus))\n",
    "o = net(input)\n",
    "o\n",
    "max_i = -1\n",
    "for i in range(len(o)):\n",
    "    if o[i].item() > o[max_i].item():\n",
    "        max_i = i\n",
    "max_i\n",
    "corpus[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'eats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[446], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m generation \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meats\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     l \u001b[38;5;241m=\u001b[39m words_around(torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mfloat\u001b[39m(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[43mword_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(dim)]))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# l1 = l[len(l)//2:]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     l1 \u001b[38;5;241m=\u001b[39m l\n",
      "\u001b[0;31mKeyError\u001b[0m: 'eats'"
     ]
    }
   ],
   "source": [
    "generation = [\"eats\"]\n",
    "for _ in range(5):\n",
    "    l = words_around(torch.tensor([float(a) for a in word_dict[generation[-1]]] + [float(a) for a in np.zeros(dim)]))\n",
    "    # l1 = l[len(l)//2:]\n",
    "    l1 = l\n",
    "    max_index = -1\n",
    "    for i in range(len(l1)):\n",
    "        if l1[i] >= l1[max_index]:\n",
    "            max_index = i\n",
    "    generation.append(corpus[max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eats', 'the', 'cat', 'not', 'the', 'cat']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mano'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Code/Embeddings Project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mano'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[258], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmano\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/Embeddings Project/.venv/lib/python3.11/site-packages/pandas/core/series.py:1112\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/Documents/Code/Embeddings Project/.venv/lib/python3.11/site-packages/pandas/core/series.py:1228\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1228\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Documents/Code/Embeddings Project/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mano'"
     ]
    }
   ],
   "source": [
    "pd.Series(text).value_counts()['mano']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings(word):\n",
    "    return [v.item() for v in net.embeddings(torch.tensor(word_dict[word]))]\n",
    "def cos_similarity(a, b):\n",
    "    s = 0\n",
    "    for i in range(len(a)):\n",
    "        s += a[i] * b[i]\n",
    "    s /= sum(e**2 for e in a)**0.5\n",
    "    s /= sum(e**2 for e in b)**0.5\n",
    "    return s\n",
    "emb = [embeddings(word) for word in corpus]\n",
    "ref = embeddings(\"noticed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_i = -1\n",
    "for i in range(len(corpus)):\n",
    "    s = cos_similarity(emb[i], ref)\n",
    "    if s != 0 and s <= cos_similarity(emb[min_i], ref):\n",
    "        min_i = i\n",
    "print(corpus[min_i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
