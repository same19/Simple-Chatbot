{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "\n",
    "https://github.com/pytorch/examples/blob/main/word_language_model/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from net import Net_CBOW\n",
    "import numpy as np\n",
    "version = \"april27_WT2_nodatalim_10epoch_128dim_100minf\"\n",
    "\n",
    "vocab = torch.load(f\"saves/vocab_{version}.pt\")\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_id(word, vocab=vocab):\n",
    "    if word not in vocab:\n",
    "        return vocab[\"<unk>\"]\n",
    "    return vocab[word]\n",
    "def lookup_token(word_id, vocab=vocab):\n",
    "    for word in vocab:\n",
    "        if vocab[word] == word_id:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "wikitext2 = load_dataset(\"wikitext\", \"wikitext-2-v1\")\n",
    "text_train = wikitext2[\"train\"]['text']\n",
    "text_train = [item.lower().strip() for item in text_train if len(item) > 0]\n",
    "text_test = wikitext2[\"test\"]['text']\n",
    "text_test = [item.lower().strip() for item in text_test if len(item) > 0]\n",
    "len(text_test)\n",
    "text_train = [item.split(\" \") + [\"\\n\"] for item in text_train if \"=\" not in item]\n",
    "text_test = [item.split(\" \") + [\"\\n\"] for item in text_test if \"=\" not in item]\n",
    "\n",
    "seq_length = 128\n",
    "buffer = 20\n",
    "\n",
    "x_train = [[lookup_id(word) for word in paragraph[len(paragraph)-seq_length-1:len(paragraph)-1]] for paragraph in text_train if len(paragraph) >= seq_length + buffer+1]\n",
    "y_train = [[lookup_id(word) for word in paragraph[len(paragraph)-seq_length:len(paragraph)]] for paragraph in text_train if len(paragraph) >= seq_length + buffer+1]\n",
    "x_test = [[lookup_id(word) for word in paragraph[len(paragraph)-seq_length-1:len(paragraph)-1]] for paragraph in text_test if len(paragraph) >= seq_length + buffer+1]\n",
    "y_test = [[lookup_id(word) for word in paragraph[len(paragraph)-seq_length:len(paragraph)]] for paragraph in text_test if len(paragraph) >= seq_length + buffer+1]\n",
    "# print([[word for word in paragraph[start_i:max_seq_length]] for paragraph in text_train if len(paragraph) >= max_seq_length + start_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', 'as', 'they', 'are', '<unk>', '.', 'the', 'route', 'to', 'each', 'story', 'location', 'on', 'the', '<unk>', '<unk>', '<unk>', 'on', 'an', 'individual', 'player', \"'s\", 'approach', ':', 'when', 'one', '<unk>', 'is', 'selected', ',', 'the', 'other', 'is', '<unk>', 'off', 'to', 'the', 'player', '.', 'outside', '<unk>', ',', 'the', 'player', 'characters', 'rest', 'in', 'a', 'camp', ',', 'where', 'units', 'can', 'be', '<unk>', 'and', 'character', 'growth', '<unk>', '.', 'alongside', 'the', 'main', 'story', '<unk>', 'are', 'character', '@-@', 'specific', '<unk>', '<unk>', '<unk>', 'to', 'different', '<unk>', 'members', '.', 'after', 'the', 'game', \"'s\", '<unk>', ',', 'additional', 'episodes', 'are', '<unk>', ',', 'some', 'of', 'them', 'having', 'a', 'higher', '<unk>', 'than', 'those', 'found', 'in', 'the', 'rest', 'of', 'the', 'game', '.', 'there', 'are', 'also', 'love', '<unk>', 'elements', 'related', 'to', 'the', 'game', \"'s\", 'two', 'main', '<unk>', ',', 'although', 'they', 'take', 'a', 'very', 'minor', 'role', '.']\n",
      "['as', 'they', 'are', '<unk>', '.', 'the', 'route', 'to', 'each', 'story', 'location', 'on', 'the', '<unk>', '<unk>', '<unk>', 'on', 'an', 'individual', 'player', \"'s\", 'approach', ':', 'when', 'one', '<unk>', 'is', 'selected', ',', 'the', 'other', 'is', '<unk>', 'off', 'to', 'the', 'player', '.', 'outside', '<unk>', ',', 'the', 'player', 'characters', 'rest', 'in', 'a', 'camp', ',', 'where', 'units', 'can', 'be', '<unk>', 'and', 'character', 'growth', '<unk>', '.', 'alongside', 'the', 'main', 'story', '<unk>', 'are', 'character', '@-@', 'specific', '<unk>', '<unk>', '<unk>', 'to', 'different', '<unk>', 'members', '.', 'after', 'the', 'game', \"'s\", '<unk>', ',', 'additional', 'episodes', 'are', '<unk>', ',', 'some', 'of', 'them', 'having', 'a', 'higher', '<unk>', 'than', 'those', 'found', 'in', 'the', 'rest', 'of', 'the', 'game', '.', 'there', 'are', 'also', 'love', '<unk>', 'elements', 'related', 'to', 'the', 'game', \"'s\", 'two', 'main', '<unk>', ',', 'although', 'they', 'take', 'a', 'very', 'minor', 'role', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "print([lookup_token(i) for i in x_train[0]])\n",
    "print([lookup_token(i) for i in y_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train\n",
    "y_train = y_train\n",
    "x_test = x_test[:100]\n",
    "x_test = x_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5245\n",
      "149417 671360 0.2225586868446139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5245"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_size = len(vocab)\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_feedfoward = 2048\n",
    "dropout = 0.5\n",
    "\n",
    "transformer = TransformerModel(ntoken = v_size, ninp = d_model, nhead = num_heads, nhid = d_feedfoward, nlayers = num_layers, dropout = dropout)\n",
    "\n",
    "print(len(x_train))\n",
    "x_train = x_train\n",
    "y_train = y_train\n",
    "src_data = torch.tensor(x_train)\n",
    "\n",
    "unk_id = lookup_id(\"<unk>\")\n",
    "count_unk = sum(sum((i == unk_id) for i in paragraph) for paragraph in src_data).item()\n",
    "count_total = sum(sum(1 for i in paragraph) for paragraph in src_data)\n",
    "print(count_unk, count_total, count_unk/count_total)\n",
    "\n",
    "# a = torch.randint(1, src_vocab_size, (64, max_seq_length))\n",
    "# print(a[:, 1:])\n",
    "# print(a[:, :-1])\n",
    "len(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches per epoch: 5245\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||^^^\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# print(target.view(-1).shape)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# print(\"________\")\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 31\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/Code/Simple Chatbot/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/Simple Chatbot/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Documents/Code/Simple Chatbot/.venv/lib/python3.11/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documents/Code/Simple Chatbot/.venv/lib/python3.11/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/Simple Chatbot/.venv/lib/python3.11/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "batch_size = 20\n",
    "num_batches = len(x_train) // batch_size\n",
    "print(\"Batches per epoch:\", num_batches)\n",
    "\n",
    "percent_data_per_epoch = 1\n",
    "\n",
    "indices = list(range(len(x_train)))\n",
    "for epoch in range(20):\n",
    "    train_loss = 0\n",
    "    x_train_copy = [x_train[indices[i]] for i in range(len(indices))]\n",
    "    y_train_copy = [y_train[indices[i]] for i in range(len(indices))]\n",
    "    for batch in range(int(num_batches * percent_data_per_epoch)):\n",
    "        if batch == 400:\n",
    "            print(\"^^^\")\n",
    "        source = torch.tensor(x_train_copy[batch*batch_size:(batch+1)*batch_size])  # (batch_size, seq_length)\n",
    "        target = torch.tensor(y_train_copy[batch*batch_size:(batch+1)*batch_size])  # (batch_size, seq_length)\n",
    "        optimizer.zero_grad()\n",
    "        output = transformer(source)\n",
    "        output = output.view(-1, v_size)\n",
    "        loss = criterion(output, target.view(-1))\n",
    "        # print(output.shape)\n",
    "        # print(target.view(-1).shape)\n",
    "        # print(\"________\")\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"|\", end=\"\")\n",
    "        train_loss += loss.item()\n",
    "    print(\" -> \", end='')\n",
    "    #eval\n",
    "    test_loss = 0\n",
    "    count_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for datax, datay in zip(x_test,y_test):\n",
    "            source = torch.tensor([datax])\n",
    "            target = torch.tensor([datay]).view(-1)\n",
    "            output = transformer(source)\n",
    "            output = output.view(-1, v_size)\n",
    "            test_loss += criterion(output, target).item() * len(datax)\n",
    "            count_loss += len(datax)\n",
    "    test_loss /= count_loss\n",
    "\n",
    "    train_loss /= int(num_batches * percent_data_per_epoch)\n",
    "    random.shuffle(indices)\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}\")\n",
    "\n",
    "torch.save(transformer, \"saves/model_transformer_apr30_0230pm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(transformer, \"saves/model_transformer_apr29_1200pm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['control', 'of', 'a', 'military', 'unit', 'and', 'take', 'part', 'in', '<unk>', 'against', 'enemy', 'forces', '.', 'stories', 'are', 'told', 'through', 'comic', 'book', '@-@', 'like', '<unk>', 'with', '<unk>', 'character', '<unk>', ',', 'with', 'characters', '<unk>', '<unk>', 'through', '<unk>', '<unk>', '<unk>', 'and', '<unk>', 'through', '<unk>', 'text', '.', 'the', 'player', '<unk>', 'through', 'a', 'series', 'of', '<unk>', '<unk>', ',', 'gradually', '<unk>', 'as', '<unk>', 'that', 'can', 'be', '<unk>', '<unk>', 'through', 'and', '<unk>', 'as', 'they', 'are', '<unk>', '.', 'the', 'route', 'to', 'each', 'story', 'location', 'on', 'the', '<unk>', '<unk>', '<unk>', 'on', 'an', 'individual', 'player', \"'s\", 'approach', ':', 'when', 'one', '<unk>', 'is', 'selected', ',', 'the', 'other', 'is', '<unk>', 'off', 'to', 'the', 'player', '.', 'outside', '<unk>', ',', 'the', 'player', 'characters', 'rest', 'in', 'a', 'camp', ',', 'where', 'units', 'can', 'be', '<unk>', 'and', 'character', 'growth', '<unk>', '.', 'alongside', 'the', 'main', 'story', '<unk>']\n",
      "['of', 'a', 'series', 'unit', 'and', 'take', 'part', 'in', 'a', 'chinese', 'enemy', 'forces', '.', 'alongside', 'are', 'told', 'through', 'comic', 'book', '@-@', 'like', 'herself', 'bottom', 'characters', 'as', 'growth', 'takes', 'gradually', 'characters', 'rest', 'wild', 'k', 'comic', 'off', 'order', 'that', 'take', 'off', 'comic', 'that', '.', 'outside', 'other', \"'s\", 'another', 'comic', 'military', 'of', 'a', 'prominent', 'winter', 'with', 'mario', 'commercial', 'they', 'mostly', 'can', 'be', '<unk>', 'through', 'unlike', 'comic', 'take', 'ross', 'they', 'are', 'told', 'operated', 'forced', 'other', 'to', 'each', 'story', 'location', 'on', 'an', 'player', 'off', 'against', 'text', 'an', 'individual', 'player', \"'s\", 'approach', ':', 'when', 'one', '<unk>', 'off', 'selected', ',', 'where', 'route', 'is', 'selected', 'text', 'to', 'each', 'main', \"'s\", 'stories', 'south', 'against', 'without', 'route', 'characters', 'rest', 'in', 'a', 'camp', ',', 'where', 'units', 'can', 'be', '<unk>', 'pre', 'take', 'growth', 'scoring', 'that', 'eva', 'followed', 'main', 'story', 'location', 'life']\n"
     ]
    }
   ],
   "source": [
    "o = transformer(src_data[0:1])\n",
    "sm = np.array(torch.softmax(o, 1)[0].detach())\n",
    "ids = [list(v).index(max(v)) for v in sm]\n",
    "words = [lookup_token(i) for i in ids]\n",
    "print([lookup_token(i) for i in src_data[0]])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are a <unk> <unk> . <unk> the following <unk> .\n",
      "['after', 'it', 'are', 'a', 'this']\n",
      "[0.008957216, 0.013795887, 0.01188761, 0.11148329, 0.016574614]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a\n",
      "['a', 'few', 'large', 'small', '\"']\n",
      "[0.014941752, 0.004584193, 0.005560547, 0.005065698, 0.0033910982]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few\n",
      "['can', 'a', '.', 'are', 'is']\n",
      "[0.0043566437, 0.009275039, 0.0067396043, 0.048805617, 0.008312006]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can\n",
      "['have', 'are', 'do', 'a', 'be']\n",
      "[0.057717957, 0.035070132, 0.0101899505, 0.023004128, 0.12751704]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have\n",
      "['a', 'been', 'also', 'are', 'have']\n",
      "[0.15154977, 0.12867396, 0.006671486, 0.024408525, 0.011477391]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a\n",
      "['small', 'a', 'large', 'are', 'few']\n",
      "[0.012695176, 0.0087218555, 0.007897064, 0.006415769, 0.008232827]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large\n",
      "['are', 'have', '.', 'a', 'is']\n",
      "[0.12945305, 0.010292493, 0.00744872, 0.02018076, 0.014980078]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large .\n",
      "['they', 'are', 'this', 'after', 'a']\n",
      "[0.019157127, 0.017090844, 0.031466667, 0.014925685, 0.32724714]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they\n",
      "['also', 'found', 'have', 'are', 'can']\n",
      "[0.008092646, 0.009088459, 0.02662814, 0.33317173, 0.010756265]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also\n",
      "['been', 'a', 'have', 'are', 'also']\n",
      "[0.021032123, 0.02904975, 0.023048567, 0.04869975, 0.013803414]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have\n",
      "['also', 'been', 'are', 'a', 'have']\n",
      "[0.011146491, 0.17580204, 0.011320784, 0.21023068, 0.011357635]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been\n",
      "['used', 'are', 'also', 'found', 'a']\n",
      "[0.007852544, 0.014396482, 0.008581804, 0.028955208, 0.14886618]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found\n",
      "['they', 'a', '.', 'are', 'that']\n",
      "[0.01727171, 0.35511142, 0.021520322, 0.0510977, 0.024303798]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found .\n",
      "['are', 'there', 'they', 'this', 'a']\n",
      "[0.015704252, 0.021700885, 0.09130804, 0.036192864, 0.107594654]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found . they\n",
      "['have', 'also', 'can', 'are', 'could']\n",
      "[0.060890276, 0.0140260095, 0.0130752055, 0.34680888, 0.008936084]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found . they also\n",
      "['a', 'can', 'been', 'have', 'are']\n",
      "[0.08272033, 0.011403698, 0.02964887, 0.03986354, 0.08075382]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found . they also have\n",
      "['are', 'have', 'also', 'been', 'a']\n",
      "[0.013841829, 0.016521351, 0.011069539, 0.20542043, 0.17427863]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found . they also have a\n",
      "['small', 'more', 'large', 'few', 'are']\n",
      "[0.01935141, 0.009512894, 0.013155225, 0.014721647, 0.014153689]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found . they also have a more\n",
      "['a', 'are', '.', 'they', 'than']\n",
      "[0.007050143, 0.010846202, 0.010540224, 0.004020272, 0.11074463]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found . they also have a more than\n",
      "['they', 'a', '.', 'their', 'are']\n",
      "[0.019155845, 0.24513638, 0.024536887, 0.012115843, 0.021601006]\n",
      "you are a <unk> <unk> . <unk> the following <unk> . a few can have a large . they also have been found . they also have a more than their\n",
      "['they', 'own', '.', 'first', 'are']\n",
      "[0.0035166335, 0.018602308, 0.0073338416, 0.0044018645, 0.006253538]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(words)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(top5p[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m     chosen_word \u001b[38;5;241m=\u001b[39m words[\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChoose a word: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     27\u001b[0m     text\u001b[38;5;241m.\u001b[39mappend(lookup_id(chosen_word))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# text\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "text = \"you are a helpful assistant . Answer the following question . \"\n",
    "\n",
    "text = [lookup_id(word.lower()) for word in text.strip().split(\" \")]\n",
    "\n",
    "for count in range(50):\n",
    "    i = torch.tensor([text])\n",
    "    o = transformer(i, i)\n",
    "    sm = np.array(torch.softmax(o, 2)[0].detach())\n",
    "    top5 = [np.zeros(5) for _ in range(len(sm))]\n",
    "    top5p = [np.zeros(5) for _ in range(len(sm))]\n",
    "    for vi in range(len(sm)-1,len(sm)):\n",
    "        v = sm[vi]\n",
    "        for item in v:\n",
    "            m = top5[vi][list(top5[vi]).index(min(top5[vi]))]\n",
    "            if lookup_token(list(v).index(item)) != \"<unk>\":\n",
    "                top5[vi][list(top5[vi]).index(min(top5[vi]))] = max(m, item)\n",
    "        top5[vi] = [list(v).index(i) for i in top5[vi]]\n",
    "        top5p[vi] = [v[i] for i in top5[vi]]\n",
    "    # ids = [list(v).index(max(v)) for v in sm]\n",
    "    words = [[lookup_token(i) for i in w] for w in top5][-1]\n",
    "    # print([lookup_token(i) for i in src_data[0]])\n",
    "    # print(words)\n",
    "    print(' '.join([lookup_token(i) for i in text]))\n",
    "    print(words)\n",
    "    print(top5p[-1])\n",
    "    chosen_word = words[int(input(\"Choose a word: \"))-1]\n",
    "    text.append(lookup_id(chosen_word))\n",
    "# text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1220]])\n",
      "| Generated 0/['alongside', 'the', 'main', 'story', '<unk>', 'terms'] words\n",
      "tensor([[1074]])\n",
      "| Generated 1/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location'] words\n",
      "tensor([[4]])\n",
      "| Generated 2/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>'] words\n",
      "tensor([[4]])\n",
      "| Generated 3/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>'] words\n",
      "tensor([[489]])\n",
      "| Generated 4/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon'] words\n",
      "tensor([[1216]])\n",
      "| Generated 5/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish'] words\n",
      "tensor([[180]])\n",
      "| Generated 6/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you'] words\n",
      "tensor([[1251]])\n",
      "| Generated 7/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual'] words\n",
      "tensor([[1216]])\n",
      "| Generated 8/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish'] words\n",
      "tensor([[111]])\n",
      "| Generated 9/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through'] words\n",
      "tensor([[13]])\n",
      "| Generated 10/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on'] words\n",
      "tensor([[762]])\n",
      "| Generated 11/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry'] words\n",
      "tensor([[5]])\n",
      "| Generated 12/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and'] words\n",
      "tensor([[1431]])\n",
      "| Generated 13/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg'] words\n",
      "tensor([[122]])\n",
      "| Generated 14/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against'] words\n",
      "tensor([[703]])\n",
      "| Generated 15/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.'] words\n",
      "tensor([[2154]])\n",
      "| Generated 16/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.', 'join'] words\n",
      "tensor([[122]])\n",
      "| Generated 17/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.', 'join', 'against'] words\n",
      "tensor([[1772]])\n",
      "| Generated 18/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.', 'join', 'against', 'hamels'] words\n",
      "tensor([[283]])\n",
      "| Generated 19/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.', 'join', 'against', 'hamels', 'player'] words\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ntokens = len(vocab)\n",
    "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
    "model = transformer\n",
    "temperature = 2\n",
    "log_interval = 1\n",
    "input = 'alongside the main story <unk>'\n",
    "input = [lookup_id(i) for i in input.strip().split(\" \")]\n",
    "input = torch.tensor(input).view(len(input), 1)\n",
    "\n",
    "\n",
    "with open('out_generation.txt', 'w') as outf:\n",
    "    with torch.no_grad():  # no tracking history\n",
    "        for i in range(20):\n",
    "            output = model(input, False)\n",
    "            word_weights = output[-1].squeeze().div(temperature).exp().cpu()\n",
    "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "            word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
    "            print(word_tensor)\n",
    "            input = torch.cat([input, word_tensor], 0)\n",
    "\n",
    "            word = lookup_token(word_idx)\n",
    "\n",
    "            outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
    "\n",
    "            if i % log_interval == 0:\n",
    "                print('| Generated {}/{} words'.format(i, [lookup_token(i[0])for i in input]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
