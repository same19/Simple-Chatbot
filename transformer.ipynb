{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "\n",
    "https://github.com/pytorch/examples/blob/main/word_language_model/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6908"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from net import Net_CBOW\n",
    "import numpy as np\n",
    "version = \"april27_WT2_nodatalim_10epoch_128dim_100minf\"\n",
    "\n",
    "# vocab = torch.load(f\"saves/vocab_{version}.pt\")\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vocab, \"saves/vocab_may1_WT2_transformer_min25f.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6908"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "wikitext2 = load_dataset(\"wikitext\", \"wikitext-2-v1\")\n",
    "\n",
    "DATA_SPLIT = \"train\"\n",
    "text = wikitext2[DATA_SPLIT]['text']\n",
    "text = [item.lower().strip() for item in text if len(item) > 0]\n",
    "text = [item.split(\" \") + [\"\\n\"] for item in text if \"=\" not in item]\n",
    "# Prepare Corpus\n",
    "DATA_LIMIT = None #paragraph limit\n",
    "all_words = []\n",
    "for paragraph in text[:DATA_LIMIT]:\n",
    "    all_words += paragraph\n",
    "all_words = pd.Series(all_words)\n",
    "len(all_words)\n",
    "len(all_words.unique())\n",
    "\n",
    "v_counts = all_words.value_counts()\n",
    "\n",
    "#filter out rare words\n",
    "N_times = 25 #shows up in 100 different paragraphs\n",
    "# v_counts = all_words.value_counts()\n",
    "corpus = pd.Series([key for key in v_counts.keys() if v_counts[key] >= N_times])\n",
    "corpus\n",
    "vocab = {}\n",
    "for i in range(len(corpus)):\n",
    "    vocab[corpus[i]] = i\n",
    "len(vocab)\n",
    "#6908"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load(\"saves/vocab_may1_WT2_transformer_min25f.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_id(word, vocab=vocab):\n",
    "    if word not in vocab:\n",
    "        return vocab[\"<unk>\"]\n",
    "    return vocab[word]\n",
    "def lookup_token(word_id, vocab=vocab):\n",
    "    for word in vocab:\n",
    "        if vocab[word] == word_id:\n",
    "            return word\n",
    "    return \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['5', '6', '7', '8', '9', '8', '9', 'a', 'b']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_list(l, item, include_item = False):\n",
    "    particular_value = item\n",
    "    result = []\n",
    "    temp_list = []\n",
    "    for i in l:\n",
    "        if i == particular_value:\n",
    "            if include_item:\n",
    "                temp_list.append(i)\n",
    "            result.append(temp_list)\n",
    "            temp_list = []\n",
    "        else:\n",
    "            temp_list.append(i)\n",
    "    result.append(temp_list)\n",
    "    return result\n",
    "split_list([\"5\", \"6\", \"7\", \"8\", \"9\", \"8\", \"9\", \"a\", \"b\"], \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregengel/Documents/GitHub/Simple-Chatbot/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/gregengel/Documents/GitHub/Simple-Chatbot/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 10.5k/10.5k [00:00<00:00, 14.4MB/s]\n",
      "Downloading data: 100%|██████████| 722k/722k [00:00<00:00, 1.83MB/s]\n",
      "Downloading data: 100%|██████████| 156M/156M [00:04<00:00, 37.2MB/s] \n",
      "Downloading data: 100%|██████████| 156M/156M [00:03<00:00, 39.6MB/s] \n",
      "Downloading data: 100%|██████████| 655k/655k [00:00<00:00, 3.65MB/s]\n",
      "Generating test split: 100%|██████████| 4358/4358 [00:00<00:00, 451428.14 examples/s]\n",
      "Generating train split: 100%|██████████| 1801350/1801350 [00:00<00:00, 3552481.01 examples/s]\n",
      "Generating validation split: 100%|██████████| 3760/3760 [00:00<00:00, 1644653.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "wikitext2 = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
    "text_train = wikitext2[\"train\"]['text']\n",
    "text_train = [item.lower().strip() for item in text_train if len(item) > 0]\n",
    "text_test = wikitext2[\"test\"]['text']\n",
    "text_test = [item.lower().strip() for item in text_test if len(item) > 0]\n",
    "# len(text_test)\n",
    "text_train = [item.split(\" \") + [\"\\n\"] for item in text_train if \"=\" not in item]\n",
    "text_test = [item.split(\" \") + [\"\\n\"] for item in text_test if \"=\" not in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 761, 342274)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max_seq_length = 128\n",
    "buffer = 0\n",
    "\n",
    "# x_train = [[lookup_id(word) for word in split_list(paragraph, \".\", True)[1]] for paragraph in text_train if len(split_list(paragraph, \".\", True))>=3]\n",
    "# y_train = [item[1:] for item in x_train]\n",
    "# x_train = [item[:-1] for item in x_train]\n",
    "\n",
    "# x_test = [[lookup_id(word) for word in split_list(paragraph, \".\", True)[1]] for paragraph in text_test if len(split_list(paragraph, \".\", True))>=3]\n",
    "# print(len(x_test))\n",
    "# y_test = [item[1:] for item in x_test]\n",
    "# x_test = [item[:-1] for item in x_test]\n",
    "def seq_length():\n",
    "    return random.randint(5, max_seq_length)\n",
    "\n",
    "x_train = [[lookup_id(word) for word in paragraph[:max_seq_length+1]] for paragraph in text_train if len(paragraph) >= max_seq_length + buffer+1]\n",
    "y_train = [item[1:] for item in x_train]\n",
    "x_train = [item[:-1] for item in x_train]\n",
    "print(\"-->\")\n",
    "x_test = [[lookup_id(word) for word in paragraph[:seq_length()+1]] for paragraph in text_test if len(paragraph) >= max_seq_length + buffer+1]\n",
    "y_test = [item[1:] for item in x_test]\n",
    "x_test = [item[:-1] for item in x_test]\n",
    "len(x_test[0]), len(x_test), len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', 'had', 'a', 'pet', 'common', 'starling', 'which', 'could', 'sing', 'part', 'of', 'his', 'piano', '<unk>', 'in', 'g', 'major', '(', '<unk>', '.', '<unk>', ')', '.', 'he', 'had', 'bought', 'it', 'from', 'a', 'shop', 'after', 'hearing', 'it', 'sing', 'a', 'phrase', 'from', 'a', 'work', 'he', 'wrote', 'six', 'weeks', 'previously', ',', 'which', 'had', 'not', 'yet', 'been', 'performed', 'in', 'public', '.', 'he', 'became', 'very', 'attached', 'to', 'the', 'bird', 'and', 'arranged', 'an', 'elaborate', 'funeral', 'for', 'it', 'when', 'it', 'died', 'three', 'years', 'later', '.', 'it', 'has', 'been', 'suggested', 'that', 'his', 'a', 'musical', '<unk>', '(', 'k.', '<unk>', ')', 'might', 'be', 'written', 'in', 'the', '<unk>', ',', '<unk>', 'style', 'of', 'a', 'starling', \"'s\", '<unk>', '.', 'other', 'people', 'who', 'have', 'owned', 'common', 'starlings', 'report', 'how', '<unk>', 'they', 'are', 'at', '<unk>', 'up', '<unk>', 'and', '<unk>', '.', 'the', 'words', 'have', 'no', 'meaning', 'for']\n",
      "['had', 'a', 'pet', 'common', 'starling', 'which', 'could', 'sing', 'part', 'of', 'his', 'piano', '<unk>', 'in', 'g', 'major', '(', '<unk>', '.', '<unk>', ')', '.', 'he', 'had', 'bought', 'it', 'from', 'a', 'shop', 'after', 'hearing', 'it', 'sing', 'a', 'phrase', 'from', 'a', 'work', 'he', 'wrote', 'six', 'weeks', 'previously', ',', 'which', 'had', 'not', 'yet', 'been', 'performed', 'in', 'public', '.', 'he', 'became', 'very', 'attached', 'to', 'the', 'bird', 'and', 'arranged', 'an', 'elaborate', 'funeral', 'for', 'it', 'when', 'it', 'died', 'three', 'years', 'later', '.', 'it', 'has', 'been', 'suggested', 'that', 'his', 'a', 'musical', '<unk>', '(', 'k.', '<unk>', ')', 'might', 'be', 'written', 'in', 'the', '<unk>', ',', '<unk>', 'style', 'of', 'a', 'starling', \"'s\", '<unk>', '.', 'other', 'people', 'who', 'have', 'owned', 'common', 'starlings', 'report', 'how', '<unk>', 'they', 'are', 'at', '<unk>', 'up', '<unk>', 'and', '<unk>', '.', 'the', 'words', 'have', 'no', 'meaning', 'for', 'the']\n"
     ]
    }
   ],
   "source": [
    "print([lookup_token(i) for i in x_train[6871]])\n",
    "print([lookup_token(i) for i in y_train[6871]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[6872:]\n",
    "y_train = y_train[6872:]\n",
    "x_test = x_test[:200]\n",
    "y_test = y_test[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_size = len(vocab)\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_feedfoward = 2048\n",
    "dropout = 0.5\n",
    "\n",
    "# transformer = TransformerModel(ntoken = v_size, ninp = d_model, nhead = num_heads, nhid = d_feedfoward, nlayers = num_layers, dropout = dropout)\n",
    "\n",
    "print(len(x_train))\n",
    "x_train = x_train\n",
    "y_train = y_train\n",
    "# src_data = torch.tensor(x_train)\n",
    "\n",
    "# unk_id = lookup_id(\"<unk>\")\n",
    "# count_unk = sum(sum((i == unk_id) for i in paragraph) for paragraph in x_train).item()\n",
    "# count_total = sum(sum(1 for i in paragraph) for paragraph in x_train)\n",
    "# print(count_unk, count_total, count_unk/count_total)\n",
    "\n",
    "# a = torch.randint(1, src_vocab_size, (64, max_seq_length))\n",
    "# print(a[:, 1:])\n",
    "# print(a[:, :-1])\n",
    "len(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches per epoch: 838.5\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| -> Epoch: 1, Train Loss: 5.060751532769018, Test Loss: 4.998311252736597\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| -> Epoch: 2, Train Loss: 4.997183613728823, Test Loss: 4.951051213737949\n",
      "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| -> Epoch: 3, Train Loss: 4.962328541868843, Test Loss: 4.926154599658159\n"
     ]
    }
   ],
   "source": [
    "net_file = \"saves/model_transformer_may3_1200am.pt\"\n",
    "transformer = torch.load(\"saves/model_transformer_may2_0600pm.pt\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.00002, betas=(0.9, 0.98), eps=1e-9) #normal lr is 0.0001\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "batch_size = 40\n",
    "num_batches = len(x_train) // batch_size\n",
    "BATCH_PRINT_SIZE = 10\n",
    "print(\"Batches per epoch:\", num_batches/BATCH_PRINT_SIZE)\n",
    "\n",
    "percent_data_per_epoch = 1\n",
    "\n",
    "indices = list(range(len(x_train)))\n",
    "for epoch in range(3):\n",
    "    train_loss = 0\n",
    "    x_train_copy = [x_train[indices[i]] for i in range(len(indices))]\n",
    "    y_train_copy = [y_train[indices[i]] for i in range(len(indices))]\n",
    "    for batch in range(int(num_batches * percent_data_per_epoch)):\n",
    "        source = torch.tensor(x_train_copy[batch*batch_size:(batch+1)*batch_size])  # (batch_size, seq_length)\n",
    "        target = torch.tensor(y_train_copy[batch*batch_size:(batch+1)*batch_size])  # (batch_size, seq_length)\n",
    "        # print(source)\n",
    "        # print(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = transformer(source)\n",
    "        output = output.view(-1, v_size)\n",
    "        loss = criterion(output, target.view(-1))\n",
    "        # print(output.shape)\n",
    "        # print(target.view(-1).shape)\n",
    "        # print(\"________\")\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % BATCH_PRINT_SIZE == 0:\n",
    "            print(\"|\", end=\"\")\n",
    "        train_loss += loss.item()\n",
    "    print(\" -> \", end='')\n",
    "    #eval\n",
    "    test_loss = 0\n",
    "    count_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for datax, datay in zip(x_test,y_test):\n",
    "            source = torch.tensor([datax])\n",
    "            target = torch.tensor([datay]).view(-1)\n",
    "            output = transformer(source)\n",
    "            output = output.view(-1, v_size)\n",
    "            test_loss += criterion(output, target).item() * len(datax)\n",
    "            count_loss += len(datax)\n",
    "    test_loss /= count_loss\n",
    "\n",
    "    train_loss /= int(num_batches * percent_data_per_epoch)\n",
    "    random.shuffle(indices)\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}\")\n",
    "torch.save(transformer, net_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_file = \"saves/model_transformer_may1_1250pm.pt\"\n",
    "# torch.save(transformer, net_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['card', '.', 'the', '<unk>', 'were', 'performed', 'on', 'the', 'fastra', 'ii', ',', 'the', 'fastra', 'i', ',', 'a', '<unk>', '@-@', 'core', '<unk>', '(', 'consisting', 'of', '<unk>', '<unk>', ')', ',', 'an', '<unk>', '<unk>', '<unk>', '<unk>', 'card', 'on', 'an', '<unk>', 'core', '<unk>', '<unk>', '<unk>', ',', 'and', 'on', 'an', '<unk>', 'core', '<unk>', '<unk>', '<unk>', 'itself', '.', 'the', 'fastra', 'ii', 'is', 'over', 'three', 'times', 'faster', 'than', 'the', 'fastra', 'i', 'in', '<unk>', '<unk>', 'reconstruction', 'speed', '.', 'although', 'the', 'fastra', 'ii', '<unk>', 'more', 'power', 'than', 'the', 'fastra', 'i', ',', 'it', \"'s\", 'nearly', '3', 'times', 'as', 'energy', '<unk>', 'as', 'the', 'fastra', 'i', ',', 'and', 'over', '300', 'times', 'as', 'energy', '<unk>', 'as', 'the', '<unk>', '@-@', 'core', '<unk>', '.', 'the', 'video', 'cards', 'run', 'at', '37', 'degrees', '<unk>', 'when', '<unk>', ',', 'and', 'at', '60', 'degrees', '<unk>', 'at', 'full', 'load', '.']\n",
      "['with', 'john', 'largest', ';', 'not', ':', '5', 'main', 'share', 'were', 'but', 'british', '@-@', 'had', '08', 'total', 'by', 'prince', 'tends', 'government', '14', 'of', 'them', 'road', 'appearances', 'were', 'including', 'irish', 'relegated', '@-@', '.', 'at', 'by', '24', 'earthquake', 'for', '\"', '.', 'destroyers', 'trapped', 'hebrew', 'membrane', '7', 'earthquake', '@-@', 'of', 'km', 'on', '.', 'mole', 'along', 'first', '@-@', 'system', 'one', 'parrot', 'months', 'among', 'are', 'conclusion', 'title', 'million', 'destroyed', 'september', 'partial', 'efforts', 'at', 'of', 'prison', 'he', 'first', ',', 'of', '(', 'destroyers', \"'s\", 'he', 'series', 'fiction', 'had', 'which', 'now', 'own', '1', '@.@', 'in', 'those', 'to', 'and', '2009', 'old', 'mammals', 'had', 'sinclair', '1896', 'blacks', 'walk', 'by', 'a', 'barker', 'because', 'well', 'largest', 'following', 'au', 'measures', ')', 'sean', 'first', 'made', 'electricity', 'has', 'chagas', 'of', 'of', 'for', 'been', 'between', 'isbn', 'others', 'a', 'mammals', 'has', 'by', 'september', 'million', 'around', 'they']\n"
     ]
    }
   ],
   "source": [
    "o = transformer(src_data[0:1])\n",
    "sm = np.array(torch.softmax(o, 1)[0].detach())\n",
    "ids = [list(v).index(max(v)) for v in sm]\n",
    "words = [lookup_token(i) for i in ids]\n",
    "print([lookup_token(i) for i in src_data[0]])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are a <unk> assistant . answer the following question .\n",
      "['in', 'a', 'he', '\"', 'on']\n",
      "[0.082577735, 0.024254575, 0.043053746, 0.033439506, 0.025467215]\n",
      "you are a <unk> assistant . answer the following question . in\n",
      "['a', 'their', 'an', 'his', 'which']\n",
      "[0.06289544, 0.013856521, 0.015006466, 0.020354144, 0.0133204125]\n",
      "you are a <unk> assistant . answer the following question . in their\n",
      "['opponents', 'first', 'way', 'home', 'own']\n",
      "[0.008090098, 0.070655584, 0.011046601, 0.0079570925, 0.059320744]\n",
      "you are a <unk> assistant . answer the following question . in their own\n",
      "['right', ',', '.', '@-@', 'and']\n",
      "[0.011739017, 0.0643455, 0.044036668, 0.00968784, 0.025577338]\n",
      "you are a <unk> assistant . answer the following question . in their own right\n",
      "['@-@', ',', '.', 'to', 'and']\n",
      "[0.09095287, 0.09226749, 0.05907558, 0.110956185, 0.04225587]\n",
      "you are a <unk> assistant . answer the following question . in their own right ,\n",
      "['in', 'a', 'which', 'but', 'and']\n",
      "[0.021232849, 0.025981423, 0.031597324, 0.034654386, 0.104052775]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a\n",
      "['\"', 'major', 'new', 'number', 'year']\n",
      "[0.020652305, 0.010631363, 0.015156078, 0.00937355, 0.008289262]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major\n",
      "['@-@', ',', '.', 'league', 'and']\n",
      "[0.020233901, 0.019255027, 0.023885723, 0.061677538, 0.010357085]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league\n",
      "['in', ',', '.', \"'s\", 'football']\n",
      "[0.07998847, 0.057753347, 0.035517372, 0.03236138, 0.039138813]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's\n",
      "['\"', ',', 'first', 'mother', 'death']\n",
      "[0.015164406, 0.007927381, 0.021160407, 0.0068572015, 0.008578179]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death\n",
      "['in', ',', '.', 'of', 'and']\n",
      "[0.07015324, 0.18154444, 0.10111651, 0.24231979, 0.023687411]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and\n",
      "['that', 'other', 'was', 'is', 'a']\n",
      "[0.0115317125, 0.0139349345, 0.011760068, 0.013139965, 0.017687777]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other\n",
      "['in', ',', '.', 'three', 'at']\n",
      "[0.014033796, 0.022129042, 0.027483696, 0.018642386, 0.016952295]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other ,\n",
      "['which', 'a', 'as', 'but', 'and']\n",
      "[0.023771917, 0.029611627, 0.021340836, 0.037493575, 0.100415975]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a\n",
      "['number', 'new', '\"', 'large', 'result']\n",
      "[0.007269793, 0.01356624, 0.024010055, 0.008145246, 0.009074053]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number\n",
      "['three', ',', 'one', 'of', '@-@']\n",
      "[0.01506158, 0.010693797, 0.011805043, 0.6171569, 0.011937738]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number ,\n",
      "['but', 'which', 'a', 'he', 'and']\n",
      "[0.037570324, 0.02214594, 0.028024746, 0.023713626, 0.06374976]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number , he\n",
      "['was', 'is', 'had', 'also', 'has']\n",
      "[0.11211537, 0.017126981, 0.08893041, 0.033947114, 0.014022829]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number , he is\n",
      "['not', 'an', 'a', 'now', 'also']\n",
      "[0.014668218, 0.026106555, 0.06531798, 0.014878522, 0.051770534]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number , he is a\n",
      "['\"', 'tropical', 'large', 'number', 'new']\n",
      "[0.019429702, 0.011449364, 0.014156285, 0.011986674, 0.011681414]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number , he is a new\n",
      "['jersey', 'york', 'year', 'south', 'zealand']\n",
      "[0.018719763, 0.11562451, 0.02516571, 0.0267465, 0.039332755]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number , he is a new york\n",
      "['in', ',', '.', \"'s\", 'and']\n",
      "[0.03242864, 0.24870577, 0.078746736, 0.031618908, 0.03763129]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number , he is a new york 's\n",
      "['\"', 'own', 'first', 'mother', 'death']\n",
      "[0.009184413, 0.005535947, 0.014651408, 0.0064668013, 0.009740657]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number , he is a new york 's mother\n",
      "[\"'s\", ',', '.', 'of', 'and']\n",
      "[0.06660922, 0.10350113, 0.0439264, 0.08168919, 0.06421676]\n",
      "you are a <unk> assistant . answer the following question . in their own right , a major league 's death and other , a number , he is a new york 's mother .\n",
      "['in', 'he', 'it', '\"', 'at']\n",
      "[0.09373901, 0.056873426, 0.0409001, 0.03261921, 0.02650641]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(words)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(top5p[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m     chosen_word \u001b[38;5;241m=\u001b[39m words[\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChoose a word: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     27\u001b[0m     text\u001b[38;5;241m.\u001b[39mappend(lookup_id(chosen_word))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# text\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "text = \"you are a helpful assistant . Answer the following question . \"\n",
    "\n",
    "text = [lookup_id(word.lower()) for word in text.strip().split(\" \")]\n",
    "\n",
    "for count in range(50):\n",
    "    i = torch.tensor([text])\n",
    "    o = transformer(i)\n",
    "    sm = np.array(torch.softmax(o, 2)[0].detach())\n",
    "    top5 = [np.zeros(5) for _ in range(len(sm))]\n",
    "    top5p = [np.zeros(5) for _ in range(len(sm))]\n",
    "    for vi in range(len(sm)-1,len(sm)):\n",
    "        v = sm[vi]\n",
    "        for item in v:\n",
    "            m = top5[vi][list(top5[vi]).index(min(top5[vi]))]\n",
    "            if lookup_token(list(v).index(item)) != \"<unk>\":\n",
    "                top5[vi][list(top5[vi]).index(min(top5[vi]))] = max(m, item)\n",
    "        top5[vi] = [list(v).index(i) for i in top5[vi]]\n",
    "        top5p[vi] = [v[i] for i in top5[vi]]\n",
    "    # ids = [list(v).index(max(v)) for v in sm]\n",
    "    words = [[lookup_token(i) for i in w] for w in top5][-1]\n",
    "    # print([lookup_token(i) for i in src_data[0]])\n",
    "    # print(words)\n",
    "    print(' '.join([lookup_token(i) for i in text]))\n",
    "    print(words)\n",
    "    print(top5p[-1])\n",
    "    chosen_word = words[int(input(\"Choose a word: \"))-1]\n",
    "    text.append(lookup_id(chosen_word))\n",
    "# text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1220]])\n",
      "| Generated 0/['alongside', 'the', 'main', 'story', '<unk>', 'terms'] words\n",
      "tensor([[1074]])\n",
      "| Generated 1/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location'] words\n",
      "tensor([[4]])\n",
      "| Generated 2/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>'] words\n",
      "tensor([[4]])\n",
      "| Generated 3/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>'] words\n",
      "tensor([[489]])\n",
      "| Generated 4/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon'] words\n",
      "tensor([[1216]])\n",
      "| Generated 5/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish'] words\n",
      "tensor([[180]])\n",
      "| Generated 6/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you'] words\n",
      "tensor([[1251]])\n",
      "| Generated 7/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual'] words\n",
      "tensor([[1216]])\n",
      "| Generated 8/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish'] words\n",
      "tensor([[111]])\n",
      "| Generated 9/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through'] words\n",
      "tensor([[13]])\n",
      "| Generated 10/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on'] words\n",
      "tensor([[762]])\n",
      "| Generated 11/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry'] words\n",
      "tensor([[5]])\n",
      "| Generated 12/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and'] words\n",
      "tensor([[1431]])\n",
      "| Generated 13/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg'] words\n",
      "tensor([[122]])\n",
      "| Generated 14/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against'] words\n",
      "tensor([[703]])\n",
      "| Generated 15/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.'] words\n",
      "tensor([[2154]])\n",
      "| Generated 16/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.', 'join'] words\n",
      "tensor([[122]])\n",
      "| Generated 17/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.', 'join', 'against'] words\n",
      "tensor([[1772]])\n",
      "| Generated 18/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.', 'join', 'against', 'hamels'] words\n",
      "tensor([[283]])\n",
      "| Generated 19/['alongside', 'the', 'main', 'story', '<unk>', 'terms', 'location', '<unk>', '<unk>', 'upon', 'spanish', 'you', 'individual', 'spanish', 'through', 'on', 'industry', 'and', 'leg', 'against', 'a.', 'join', 'against', 'hamels', 'player'] words\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "ntokens = len(vocab)\n",
    "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
    "model = transformer\n",
    "temperature = 2\n",
    "log_interval = 1\n",
    "input = 'alongside the main story <unk>'\n",
    "input = [lookup_id(i) for i in input.strip().split(\" \")]\n",
    "input = torch.tensor(input).view(len(input), 1)\n",
    "\n",
    "\n",
    "with open('out_generation.txt', 'w') as outf:\n",
    "    with torch.no_grad():  # no tracking history\n",
    "        for i in range(20):\n",
    "            output = model(input, False)\n",
    "            word_weights = output[-1].squeeze().div(temperature).exp().cpu()\n",
    "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "            word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
    "            print(word_tensor)\n",
    "            input = torch.cat([input, word_tensor], 0)\n",
    "\n",
    "            word = lookup_token(word_idx)\n",
    "\n",
    "            outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
    "\n",
    "            if i % log_interval == 0:\n",
    "                print('| Generated {}/{} words'.format(i, [lookup_token(i[0])for i in input]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
